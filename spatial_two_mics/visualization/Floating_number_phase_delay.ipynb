{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create delays with floating numbers in the input signals\n",
    "### Efthymios Tzinis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import *\n",
    "import librosa\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Customize plots\n",
    "rcParams['figure.figsize'] = (8,4)\n",
    "rcParams['lines.linewidth'] = 1\n",
    "rcParams['axes.axisbelow'] = True\n",
    "rcParams['axes.spines.right'] = False\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['font.family'] = 'Avenir Next LT Pro'\n",
    "rcParams['font.weight'] = 400\n",
    "rcParams['xtick.color'] = '#222222'\n",
    "rcParams['ytick.color'] = '#222222'\n",
    "rcParams['grid.color'] = '#dddddd'\n",
    "rcParams['grid.linestyle'] = '-'\n",
    "rcParams['grid.linewidth'] = 0.5\n",
    "rcParams['axes.titlesize'] = 11\n",
    "rcParams['axes.titleweight'] = 600\n",
    "rcParams['axes.labelsize'] = 10\n",
    "rcParams['axes.labelweight'] = 400\n",
    "rcParams['axes.linewidth'] = 0.5\n",
    "rcParams['axes.edgecolor'] = [.25,.25,.25]\n",
    "rcParams['axes.facecolor'] = '#FFFFFF00'\n",
    "rcParams['figure.facecolor'] = '#FFFFFF00'\n",
    "\n",
    "# Decent colormap\n",
    "cdict = {\t'red':   ((0.0,  1.0, 1.0), (1.0,  0.0, 0.0)),\n",
    "\t'green': ((0.0,  1.0, 1.0), (1.0,  .15, .15)),\n",
    "\t\t'blue':  ((0.0,  1.0, 1.0), (1.0,  0.4, 0.4)),\n",
    "\t\t\t'alpha': ((0.0,  0.0, 0.0), (1.0,  1.0, 1.0))}\n",
    "register_cmap(name='InvBlueA', data=cdict)\n",
    "rcParams['image.cmap'] = 'InvBlueA'\n",
    "\n",
    "# Play a sound\n",
    "def soundsc( s, r=16000, name=''):\n",
    "    from IPython.display import display, Audio, HTML\n",
    "    if name is '':\n",
    "        display( Audio( s, rate=r))\n",
    "    else:\n",
    "        display( HTML( \n",
    "        '<style> table, th, td {border: 0px; }</style> <table><tr><td>' + name + \n",
    "        '</td><td>' + Audio( s, rate=r)._repr_html_()[3:] + '</td></tr></table>'\n",
    "        ))\n",
    "\n",
    "# Clean up and redraw\n",
    "def drawnow():\n",
    "    from IPython.display import clear_output\n",
    "    clear_output( wait=True)\n",
    "    show()\n",
    "    \n",
    "# Equal and tight axis\n",
    "def axisequaltight():\n",
    "    gca().set_aspect('equal')\n",
    "    gca().autoscale(tight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from scipy.signal import stft, istft\n",
    "\n",
    "s1,sr = librosa.core.load( '/mnt/data/timit-wav/test/dr4/flbw0/sa1.wav', sr=None, mono=True)\n",
    "\n",
    "print(sr)\n",
    "s2,sr = librosa.core.load( '/mnt/data/timit-wav/test/dr4/mbns0/sa2.wav', sr=None, mono=True)\n",
    "\n",
    "print(sr)\n",
    "\n",
    "s1 = s1[:min(len(s1),len(s2))]\n",
    "s2 = s2[:min(len(s1),len(s2))]\n",
    "\n",
    "soundsc( s1, sr)\n",
    "soundsc( s2, sr)\n",
    "\n",
    "subplot( 2, 1, 1), pcolormesh( abs( stft( s1)[2])**.3)\n",
    "subplot( 2, 1, 2), pcolormesh( abs( stft( s2)[2])**.3)\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just in order to check if our loader returns the same\n",
    "import os, sys, librosa, matplotlib, plotly\n",
    "import numpy as np \n",
    "from pprint import pprint \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import FastICA\n",
    "from matplotlib.pyplot import subplot, hist, tight_layout\n",
    "from matplotlib.pylab import title\n",
    "root_dir = '../../'\n",
    "sys.path.insert(0, root_dir)\n",
    "import spatial_two_mics.examples.mixture_example as me\n",
    "import spatial_two_mics.utils.audio_mixture_constructor as mix_constructor\n",
    "import spatial_two_mics.data_generator.source_position_generator as position_generator\n",
    "import spatial_two_mics.labels_inference.tf_label_estimator as label_estimator\n",
    "from spatial_two_mics.utils import robust_means_clustering as robust_kmeans\n",
    "mixture_info = me.mixture_info_example()\n",
    "\n",
    "random_positioner = position_generator.RandomCirclePositioner()\n",
    "positions_info = random_positioner.get_sources_locations(2)\n",
    "mixture_info['positions'] = positions_info\n",
    "\n",
    "mixture_creator = mix_constructor.AudioMixtureConstructor(\n",
    "        n_fft=1024, win_len=400, hop_len=200, mixture_duration=2.0,\n",
    "        force_delays=[-1,1])\n",
    "\n",
    "tf_representations = mixture_creator.construct_mixture(mixture_info)\n",
    "\n",
    "for i, source_tf in enumerate(tf_representations['sources_tf']):\n",
    "    subplot( 2, 1, i+1), pcolormesh( abs(source_tf)**.3)\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the mixtures\n",
    "s1 = tf_representations['sources_raw'][0]\n",
    "s2 = tf_representations['sources_raw'][1]\n",
    "a = 0.3\n",
    "alphas = [a, 1. - a]\n",
    "tau = 1\n",
    "\n",
    "turbulence = 0.005\n",
    "m1 = alphas[0]*s1[:-tau] + alphas[1]*s2[tau:]\n",
    "m2 = (alphas[0]+turbulence)*s1[tau:] + (alphas[1]-turbulence)*s2[:-tau]\n",
    "m2 = (alphas[0])*s1[tau:] + (alphas[1])*s2[:-tau]\n",
    "\n",
    "n_fft = 512\n",
    "hop_length = 128\n",
    "f1 = librosa.core.stft(m1, n_fft=n_fft, hop_length=hop_length, win_length=n_fft)\n",
    "f2 = librosa.core.stft(m2, n_fft=n_fft, hop_length=hop_length, win_length=n_fft)\n",
    "# f1 = stft(m1)[2]\n",
    "# f2 = stft(m2)[2]\n",
    "\n",
    "# r = log( f1 / (f2+1e-7))\n",
    "r = f1 / (f2+1e-7)\n",
    "\n",
    "# Log amplitude difference\n",
    "a = abs( r)\n",
    "\n",
    "# Phase difference, normalized by frequency\n",
    "p = np.angle( r) / linspace( 1e-5, np.pi, f1.shape[0])[:,None]\n",
    "# p = (np.angle(f1) - np.angle(f2))/ linspace( 1e-5, pi, f1.shape[0])[:,None]\n",
    "# p = (np.angle(f1) - np.angle(f2)) / linspace( 1e-5, pi, f1.shape[0])[:,None]\n",
    "\n",
    "# Show me\n",
    "subplot( 2, 1, 1), hist( a.reshape( -1), linspace( -2, 2, 200)); title( 'Amplitude ratios')\n",
    "subplot( 2, 1, 2), hist( p.reshape( -1), linspace( -pi, pi, 200)); title( 'Normalized phases')\n",
    "# plot(), hist( p.reshape( -1), linspace( -pi, pi, 200)); title( 'Normalized phases')\n",
    "tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hist( p.reshape( -1), linspace( -pi, pi, 200)); title( 'Normalized phases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us try the same thing but with a randomly provided delay \n",
    "#  for the sources \n",
    "delays_for_sources = positions_info['taus']\n",
    "delays_for_sources = np.array([-.75, .1])\n",
    "print(delays_for_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the sinc function \n",
    "precision = 0.01\n",
    "freqs_included = 7\n",
    "xs = np.linspace(-freqs_included*sr, freqs_included*sr, \n",
    "                 2.*freqs_included/precision)\n",
    "xs = np.linspace(-freqs_included, freqs_included, \n",
    "                 2.*freqs_included/precision)\n",
    "windowed_sinc = np.sinc(xs)\n",
    "# /(1. * sr)\n",
    "plot(windowed_sinc)\n",
    "title(\"Sinc in time\")\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to convolve this window with all of the but also upsample \n",
    "signal = s1 \n",
    "sig_len = signal.shape[0]\n",
    "n_augmentation_zeros = int(1. / precision) - 1\n",
    "augmented_signal = np.zeros(sig_len + (sig_len-1)*n_augmentation_zeros)\n",
    "augmented_signal[::n_augmentation_zeros+1] = signal\n",
    "\n",
    "print(n_augmentation_zeros)     \n",
    "print(sig_len)\n",
    "subplot( 2, 1, 1), plot(signal[:15])\n",
    "subplot( 2, 1, 2), plot(augmented_signal[:15*(n_augmentation_zeros+1)])\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the convolution with the augmented signal after zero padding \n",
    "est_augmented_sig = np.convolve(augmented_signal, windowed_sinc, mode='valid')\n",
    "subplot( 2, 1, 1), plot(signal)\n",
    "subplot( 2, 1, 2), plot(est_augmented_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to make sure resample in order to check the initila signal the initial signal \n",
    "reconstructed_sig = est_augmented_sig[::n_augmentation_zeros+1]\n",
    "\n",
    "subplot( 4, 1, 1), plot(signal[freqs_included:3*freqs_included])\n",
    "subplot( 4, 1, 2), plot(augmented_signal[freqs_included*(n_augmentation_zeros+1):3*freqs_included*(n_augmentation_zeros+1)])\n",
    "subplot( 4, 1, 3), plot(est_augmented_sig[:2*freqs_included*(n_augmentation_zeros+1)])\n",
    "subplot( 4, 1, 4), plot(reconstructed_sig[:2*freqs_included]) #; title(\"Reconstructed after augmentation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now in order to make the delay we have the augmented signal \n",
    "# so we round the delays up to a specific precision we have selected \n",
    "decimals = int(np.log10(1. / precision))\n",
    "rounded_taus = np.around(delays_for_sources, decimals=decimals)\n",
    "print(decimals)\n",
    "print(rounded_taus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples needed to be rotated over the time axis in order to meet the delays that are generated \n",
    "taus_samples = int(1./precision) * rounded_taus\n",
    "taus_samples = taus_samples.astype(int)\n",
    "print(taus_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now in case of a positive delay we would have to forward the signal in the first microphone \n",
    "# or delay it otherwise by the number of samples that is defined for the corresponding source\n",
    "source_signals = [s1, s1]\n",
    "upsampling_rate = int(1. / precision)\n",
    "n_augmentation_zeros = upsampling_rate - 1\n",
    "\n",
    "mics_sources = [[], []]\n",
    "for src_id, source_sig in enumerate(source_signals):\n",
    "    sig_len = source_sig.shape[0]\n",
    "    augmented_signal = np.zeros(int(sig_len + (sig_len-1)*n_augmentation_zeros))\n",
    "    augmented_signal[::n_augmentation_zeros+1] = source_sig\n",
    "    \n",
    "    tau_in_samples = taus_samples[src_id]\n",
    "    if tau_in_samples >= 0:\n",
    "        mics_sources[0].append(est_augmented_sig[tau_in_samples:][::upsampling_rate])\n",
    "        mics_sources[1].append(est_augmented_sig[:-tau_in_samples][::upsampling_rate])\n",
    "    else:\n",
    "        mics_sources[0].append(est_augmented_sig[-tau_in_samples:][::upsampling_rate])\n",
    "        mics_sources[1].append(est_augmented_sig[:tau_in_samples][::upsampling_rate])\n",
    "\n",
    "for mic_ind, mic_sources_list in enumerate(mics_sources):\n",
    "    print(len(mic_sources_list[0]))\n",
    "    print(len(mic_sources_list[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's write it in a proper function \n",
    "def enforce_float_delays(source_signals,  \n",
    "                         delays_for_sources,\n",
    "                         fs, \n",
    "                         precision=0.01, \n",
    "                         duration=2.0, \n",
    "                         freqs_included = 5):\n",
    "    \"\"\"!\n",
    "    For 2 microphone enforce a floating point number delay with some selected precision and\n",
    "    apply that for all sources that would be given. Also make sure that the required to be \n",
    "    returned wavs have to have a length equal to the duration\"\"\"\n",
    "    upsampling_rate = int(1. / precision)\n",
    "    duration_in_samples = int(duration * fs)\n",
    "    decimals = int(np.log10(upsampling_rate))\n",
    "    \n",
    "    rounded_taus = np.around(delays_for_sources, decimals=decimals)\n",
    "    taus_samples = upsampling_rate * rounded_taus\n",
    "    taus_samples = taus_samples.astype(int)\n",
    "    \n",
    "    print(taus_samples)\n",
    "    \n",
    "    xs = np.linspace(-freqs_included, freqs_included, \n",
    "                     2.*freqs_included/precision)\n",
    "    windowed_sinc = np.sinc(xs)\n",
    "    \n",
    "    mics_sources = [[], []]\n",
    "    for src_id, source_sig in enumerate(source_signals):\n",
    "        sig_len = source_sig.shape[0]\n",
    "        augmented_signal = np.zeros(sig_len + (sig_len-1)*n_augmentation_zeros)\n",
    "        augmented_signal[::upsampling_rate] = source_sig\n",
    "        est_augmented_sig = np.convolve(augmented_signal, \n",
    "                                        windowed_sinc, \n",
    "                                        mode='valid')\n",
    "\n",
    "        tau_in_samples = taus_samples[src_id]\n",
    "        if tau_in_samples > 0:\n",
    "            source_in_mic1 = est_augmented_sig[\n",
    "                             tau_in_samples:][::upsampling_rate]\n",
    "            source_in_mic2 = est_augmented_sig[\n",
    "                             :-tau_in_samples][::upsampling_rate]\n",
    "        elif tau_in_samples < 0:\n",
    "            source_in_mic1 = est_augmented_sig[\n",
    "                             :tau_in_samples][::upsampling_rate]\n",
    "            source_in_mic2 = est_augmented_sig[\n",
    "                             -tau_in_samples:][::upsampling_rate]\n",
    "        else:\n",
    "            source_in_mic1 = est_augmented_sig[::upsampling_rate]\n",
    "            source_in_mic2 = est_augmented_sig[::upsampling_rate]\n",
    "            \n",
    "        # check the duration which is very important \n",
    "        if (len(source_in_mic1) < duration_in_samples or  \n",
    "            len(source_in_mic2) < duration_in_samples):\n",
    "            raise ValueError(\"Duration given: {} could \"\n",
    "                  \"not be sufficed before the gven source\"\n",
    "                  \" signal has a lesser duration of {} \"\n",
    "                  \"after the float delay.\".format(\n",
    "                  duration_in_samples, len(source_in_mic1)))\n",
    "            \n",
    "        mics_sources[0].append(source_in_mic1[:duration_in_samples])\n",
    "        mics_sources[1].append(source_in_mic2[:duration_in_samples])\n",
    "    \n",
    "    return mics_sources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = tf_representations['sources_raw'][0]\n",
    "s2 = tf_representations['sources_raw'][1]\n",
    "print(delays_for_sources)\n",
    "mics_sources = enforce_float_delays([s1, s2], delays_for_sources,\n",
    "                                    16000, duration=1.9, freqs_included=7, precision=0.01)\n",
    "pprint(mics_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's see how the phase changes from the previous no delay version \n",
    "m1 = alphas[0]*mics_sources[0][0] + alphas[1]*mics_sources[0][1]\n",
    "m2 = alphas[0]*mics_sources[1][0] + alphas[1]*mics_sources[1][1]\n",
    "\n",
    "n_fft = 512\n",
    "hop_length = 128\n",
    "f1_f_delayed = librosa.core.stft(m1, n_fft=n_fft, hop_length=hop_length, win_length=n_fft)\n",
    "f2_f_delayed = librosa.core.stft(m2, n_fft=n_fft, hop_length=hop_length, win_length=n_fft)\n",
    "# f1 = stft(m1)[2]\n",
    "# f2 = stft(m2)[2]\n",
    "\n",
    "# r = log( f1 / (f2+1e-7))\n",
    "r_f_delayed = f1_f_delayed / (f2_f_delayed+1e-7)\n",
    "\n",
    "# Log amplitude difference\n",
    "a_f_delayed = abs( r_f_delayed)\n",
    "\n",
    "# Phase difference, normalized by frequency\n",
    "p_f_delayed = np.angle( r_f_delayed) / linspace( 1e-5, np.pi, f1_f_delayed.shape[0])[:,None]\n",
    "# p = (np.angle(f1) - np.angle(f2))/ linspace( 1e-5, pi, f1.shape[0])[:,None]\n",
    "# p = (np.angle(f1) - np.angle(f2)) / linspace( 1e-5, pi, f1.shape[0])[:,None]\n",
    "\n",
    "# Show me\n",
    "subplot( 2, 2, 1), hist( a.reshape( -1), linspace( -2, 2, 200)); title( '[-1, 1] delays Amplitude ratios')\n",
    "subplot( 2, 2, 2), hist( p.reshape( -1), linspace( -pi, pi, 200)); title( '[-1, 1] delays Normalized phases')\n",
    "\n",
    "subplot( 2, 2, 3), hist( a_f_delayed.reshape( -1), linspace( -2, 2, 200)); title( \n",
    "                   '{} delays Amplitude ratios'.format(rounded_taus))\n",
    "subplot( 2, 2, 4), hist( p_f_delayed.reshape( -1), linspace( -pi, pi, 200)); title( \n",
    "                   '{} delays Normalized phases'.format(rounded_taus))\n",
    "# plot(), hist( p.reshape( -1), linspace( -pi, pi, 200)); title( 'Normalized phases')\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly Functions \n",
    "import plotly\n",
    "import plotly.tools as tls\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "plotly.offline.init_notebook_mode()\n",
    "\n",
    "def plot_tf_representation(tf, for_title = '', fs=16000, duration=2.0, log_scale=False):\n",
    "    freq_max, time_max = tf.shape\n",
    "    bins = np.arange(time_max)\n",
    "    bins = (duration * bins) / time_max \n",
    "    freqs = np.arange(freq_max)\n",
    "    freqs = (freqs * fs) / (2.0 * freq_max) \n",
    "    trace = [go.Heatmap(\n",
    "        x= bins,\n",
    "        y= freqs,\n",
    "#         z= 10*np.log10(Pxx),\n",
    "        z = 10*np.log10(tf) if log_scale else tf,\n",
    "        colorscale='Jet',\n",
    "        )]\n",
    "    layout = go.Layout(\n",
    "        title = 'Spectrogram '+for_title,\n",
    "        yaxis = dict(title = 'Frequency'), # x-axis label\n",
    "        xaxis = dict(title = 'Time'), # y-axis label\n",
    "        )\n",
    "    fig = dict(data=trace, layout=layout)\n",
    "    plotly.offline.iplot(fig, filename=for_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# let's check how these features go compared to the ground truth mask \n",
    "ground_truth_estimator = label_estimator.TFMaskEstimator(\n",
    "                             inference_method='Ground_truth') \n",
    "tf_representations['amplitudes'] = alphas \n",
    "tf_representations['sources_tf'] = [librosa.core.stft(mics_sources[0][0], n_fft=n_fft, \n",
    "                                                      hop_length=hop_length, win_length=n_fft), \n",
    "                                    librosa.core.stft(mics_sources[0][1], n_fft=n_fft, \n",
    "                                                      hop_length=hop_length, win_length=n_fft)]\n",
    "gt_labels = ground_truth_estimator.infer_mixture_labels(tf_representations)\n",
    "plot_tf_representation(gt_labels, for_title = 'Ground Truth Mask', log_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# now perform the analysis for duet soft labeling\n",
    "phase_dif = p_f_delayed\n",
    "n_sources = len(tf_representations['sources_tf'])\n",
    "d_feature = np.reshape(phase_dif, (np.product(phase_dif.shape), 1))\n",
    "\n",
    "used_clusters = 2\n",
    "r_kmeans = robust_kmeans.RobustKmeans(n_true_clusters=2, n_used_clusters=used_clusters)\n",
    "# kmeans = KMeans(n_clusters=clusters, random_state=7).fit(d_feature)\n",
    "d_labels = r_kmeans.fit(d_feature)\n",
    "d_feature_mask = np.reshape(d_labels, phase_dif.shape)\n",
    "plot_tf_representation(d_feature_mask, \n",
    "                       for_title = ' Phase Diff only using Robust {}-means => 2 clusters'.format(used_clusters), \n",
    "                       log_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import cycle, islice \n",
    "\n",
    "attenuation = abs(r_f_delayed)\n",
    "smoothed_attenuation = attenuation - (1. / attenuation)\n",
    "smoothed_attenuation_feature = np.reshape(smoothed_attenuation, (np.product(smoothed_attenuation.shape), 1))\n",
    "duet_features = np.concatenate((d_feature, smoothed_attenuation_feature), axis=1)\n",
    "\n",
    "used_clusters = 10\n",
    "r_kmeans = robust_kmeans.RobustKmeans(n_true_clusters=2, n_used_clusters=used_clusters)\n",
    "# kmeans = KMeans(n_clusters=clusters, random_state=7).fit(d_feature)\n",
    "duet_labels = r_kmeans.fit(duet_features)\n",
    "duet_mask = np.reshape(duet_labels, phase_dif.shape)\n",
    "plot_tf_representation(duet_mask, \n",
    "                       for_title = ' DUET features using Robust {}-means => 2 clusters'.format(used_clusters), \n",
    "                       log_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the duet features how they scatter \n",
    "gt_flatten = gt_labels.reshape(1,-1)\n",
    "xyl = np.concatenate((duet_features, gt_flatten.T), axis=1) \n",
    "\n",
    "# clip high norm values and also random sampling\n",
    "xyl = np.clip(xyl, -10., 10.)\n",
    "rand_ind = np.random.choice(np.arange(xyl.shape[0]), size=3000, replace=False)\n",
    "xyl = xyl[rand_ind, :]\n",
    "\n",
    "\n",
    "N = xyl.shape[0]\n",
    "pred0 = xyl[xyl[:,2]==0]\n",
    "pred1 = xyl[xyl[:,2]==1]\n",
    "\n",
    "title = 'Scatter of DUET features for Ground Truth Masking'\n",
    "\n",
    "trace0 = go.Scatter(\n",
    "    x = pred0[:,0],\n",
    "    y = pred0[:,1],\n",
    "    name = 'Source 1',\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 5,\n",
    "        color = 'rgba(152, 0, 0, .8)',\n",
    "        line = dict(\n",
    "            width = 2,\n",
    "            color = 'rgb(0, 0, 0)'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x = pred1[:,0],\n",
    "    y = pred1[:,1],\n",
    "    name = 'Source 2',\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 5,\n",
    "        color = 'rgba(255, 182, 193, .9)',\n",
    "        line = dict(\n",
    "            width = 2,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace0, trace1]\n",
    "\n",
    "layout = dict(title = 'Styled Scatter',\n",
    "              yaxis = dict(zeroline = False, title='Attenuation'),\n",
    "              xaxis = dict(zeroline = False, title = 'Phase Difference')\n",
    "             )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "plotly.offline.iplot(fig, filename=title)\n",
    "\n",
    "\n",
    "# duet_features = d_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now run multiple clustering algorithms in order to see how it goes:\n",
    "# gmm = mixture.GaussianMixture(\n",
    "#       n_components=n_sources, covariance_type='full')\n",
    "# spectral = cluster.SpectralClustering(\n",
    "#         n_clusters=n_sources, eigen_solver='arpack',\n",
    "#         affinity=\"nearest_neighbors\")\n",
    "# kmeans = KMeans(n_clusters=n_sources, random_state=0)\n",
    "\n",
    "# clustering_algorithms = (\n",
    "#         ('Kmeans', kmeans),\n",
    "#         ('SpectralClustering', spectral),\n",
    "#         ('GaussianMixture', gmm)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_representation(mask, gt, for_title, fs=16000., \n",
    "                            log_scale=False):\n",
    "    freq_max, time_max = mask.shape\n",
    "    bins = np.arange(time_max)\n",
    "    bins = (duration * bins) / time_max \n",
    "    freqs = np.arange(freq_max)\n",
    "    freqs = (freqs * fs) / (2.0 * freq_max) \n",
    "    trace = [go.Heatmap(\n",
    "        x= bins,\n",
    "        y= freqs,\n",
    "        z = 10*np.log10(mask) if log_scale else mask,\n",
    "        colorscale='Jet',\n",
    "        )]\n",
    "#     also plot the difference from the true mask \n",
    "    trace2 = [go.Heatmap(\n",
    "        x= bins,\n",
    "        y= freqs,\n",
    "        z = abs(mask-gt),\n",
    "        colorscale='Jet',\n",
    "        )]\n",
    "    \n",
    "    layout = go.Layout(\n",
    "        title = for_title,\n",
    "        yaxis = dict(title = 'Frequency'), # x-axis label\n",
    "        xaxis = dict(title = 'Time'), # y-axis label\n",
    "        )\n",
    "    fig = dict(data=trace, layout=layout)\n",
    "    plotly.offline.iplot(fig, filename=for_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# X = duet_features\n",
    "# plot_num = 1\n",
    "# for name, algorithm in clustering_algorithms:\n",
    "#     t0 = time.time()\n",
    "\n",
    "#     # catch warnings related to kneighbors_graph\n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.filterwarnings(\n",
    "#             \"ignore\",\n",
    "#             message=\"the number of connected components of the \" +\n",
    "#             \"connectivity matrix is [0-9]{1,2}\" +\n",
    "#             \" > 1. Completing it to avoid stopping the tree early.\",\n",
    "#             category=UserWarning)\n",
    "#         warnings.filterwarnings(\n",
    "#             \"ignore\",\n",
    "#             message=\"Graph is not fully connected, spectral embedding\" +\n",
    "#             \" may not work as expected.\",\n",
    "#             category=UserWarning)\n",
    "#         algorithm.fit(X)\n",
    "\n",
    "#     t1 = time.time()\n",
    "#     if hasattr(algorithm, 'labels_'):\n",
    "#         y_pred = algorithm.labels_\n",
    "#     else:\n",
    "#         y_pred = algorithm.predict(X)\n",
    "    \n",
    "#     duet_mask = np.reshape(y_pred, phase_dif.shape)\n",
    "#     title = 'Algorithm: {} run in {} seconds'.format(name, t1-t0 )\n",
    "# #     plot_tf_representation(duet_mask, gt_labels, title, log_scale=False)\n",
    "#     plot_tf_representation(duet_mask, for_title=title, log_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bss_eval( sep, i, sources):\n",
    "    # Current target\n",
    "    from numpy import dot, linalg, log10\n",
    "    min_len = min([len(sep), len(sources[i])])\n",
    "    sources = sources[:,:min_len]\n",
    "    sep = sep[:min_len]\n",
    "    target = sources[i]\n",
    "\n",
    "    # Target contribution\n",
    "    s_target = target * dot( target, sep.T) / dot( target, target.T)\n",
    "\n",
    "    # Interference contribution\n",
    "    pse = dot( dot( sources, sep.T), \\\n",
    "    linalg.inv( dot( sources, sources.T))).T.dot( sources)\n",
    "    e_interf = pse - s_target\n",
    "\n",
    "    # Artifact contribution\n",
    "    e_artif= sep - pse;\n",
    "\n",
    "    # Interference + artifacts contribution\n",
    "    e_total = e_interf + e_artif;\n",
    "\n",
    "    # Computation of the log energy ratios\n",
    "    sdr = 10*log10( sum( s_target**2) / sum( e_total**2));\n",
    "    sir = 10*log10( sum( s_target**2) / sum( e_interf**2));\n",
    "    sar = 10*log10( sum( (s_target + e_interf)**2) / sum( e_artif**2));\n",
    "\n",
    "    return (sdr, sir, sar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# try to evaluate the reconstructed signals \n",
    "clusters = 3 \n",
    "d_feature = np.reshape(phase_dif, (np.product(phase_dif.shape), 1))\n",
    "\n",
    "r_kmeans = robust_kmeans.RobustKmeans(n_true_clusters=2, n_used_clusters=4)\n",
    "# kmeans = KMeans(n_clusters=clusters, random_state=7).fit(d_feature)\n",
    "duet_labels = r_kmeans.fit(d_feature)\n",
    "duet_mask = np.reshape(duet_labels, phase_dif.shape)\n",
    "gt_mask = gt_labels \n",
    "\n",
    "for i in np.arange(n_sources):\n",
    "    d_stft = abs(f1_f_delayed)*(duet_mask==i).reshape(f1_f_delayed.shape)\n",
    "    gt_stft = abs(f1_f_delayed)*(gt_mask==i).reshape(f1_f_delayed.shape)\n",
    "    plot_tf_representation(d_stft, for_title='Duet reconstructed STFT')\n",
    "    plot_tf_representation(gt_stft, for_title='Ground truth reconstructed STFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_rec = []\n",
    "stft_gt = []\n",
    "\n",
    "sources = np.array([s1, s2])\n",
    "# sources = np.array([alphas[0]*s1, alphas[1]*s2])\n",
    "fs = 16000\n",
    "for i in np.arange(n_sources):\n",
    "    d_stft = f1_f_delayed*(duet_mask==i).reshape(f1_f_delayed.shape)\n",
    "    gt_stft = f1_f_delayed*(gt_mask==i).reshape(f1_f_delayed.shape)\n",
    "    \n",
    "    \n",
    "    d_s_rec = librosa.core.istft( d_stft, \n",
    "                                 hop_length=hop_length, win_length=n_fft)\n",
    "    gt_s_rec = librosa.core.istft( gt_stft, \n",
    "                                 hop_length=hop_length, win_length=n_fft)\n",
    "\n",
    "    soundsc( d_s_rec, fs, 'Librosa Duet Reconstructed Signal for Source: {}'.format(i))\n",
    "    (sdr, sir, sar) = bss_eval( d_s_rec, 0, np.array(mics_sources[0]))\n",
    "    print((sdr, sir, sar))\n",
    "    (sdr, sir, sar) = bss_eval( d_s_rec, 1, np.array(mics_sources[0]))\n",
    "    print((sdr, sir, sar))\n",
    "    \n",
    "    soundsc( gt_s_rec, fs, 'Ground Truth Reconstructed Signal for Source: {}'.format(i))\n",
    "    (sdr, sir, sar) = bss_eval( gt_s_rec, 0, np.array(mics_sources[0]))\n",
    "    print((sdr, sir, sar))\n",
    "    (sdr, sir, sar) = bss_eval( gt_s_rec, 1, np.array(mics_sources[0]))\n",
    "    print((sdr, sir, sar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
